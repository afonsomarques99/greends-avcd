{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import smacof\n",
    "\n",
    "df = pd.read_csv('EFIplus_medit.zip',compression='zip', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site_code</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Country</th>\n",
       "      <th>Catchment_name</th>\n",
       "      <th>Galiza</th>\n",
       "      <th>Subsample</th>\n",
       "      <th>Calib_EFI_Medit</th>\n",
       "      <th>Calib_connect</th>\n",
       "      <th>Calib_hydrol</th>\n",
       "      <th>...</th>\n",
       "      <th>Squalius malacitanus</th>\n",
       "      <th>Squalius pyrenaicus</th>\n",
       "      <th>Squalius torgalensis</th>\n",
       "      <th>Thymallus thymallus</th>\n",
       "      <th>Tinca tinca</th>\n",
       "      <th>Zingel asper</th>\n",
       "      <th>Squalius sp</th>\n",
       "      <th>Barbatula sp</th>\n",
       "      <th>Phoxinus sp</th>\n",
       "      <th>Iberochondrostoma_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES_01_0002</td>\n",
       "      <td>38.102003</td>\n",
       "      <td>-4.096070</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Guadalquivir</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES_02_0001</td>\n",
       "      <td>40.530188</td>\n",
       "      <td>-1.887796</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Tejo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES_02_0002</td>\n",
       "      <td>40.595432</td>\n",
       "      <td>-1.928079</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Tejo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES_02_0003</td>\n",
       "      <td>40.656184</td>\n",
       "      <td>-1.989831</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Tejo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ES_02_0004</td>\n",
       "      <td>40.676402</td>\n",
       "      <td>-2.036274</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Tejo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Site_code   Latitude  Longitude Country Catchment_name  Galiza  Subsample  \\\n",
       "0  ES_01_0002  38.102003  -4.096070   Spain   Guadalquivir       0          1   \n",
       "1  ES_02_0001  40.530188  -1.887796   Spain           Tejo       0          1   \n",
       "2  ES_02_0002  40.595432  -1.928079   Spain           Tejo       0          1   \n",
       "3  ES_02_0003  40.656184  -1.989831   Spain           Tejo       0          1   \n",
       "4  ES_02_0004  40.676402  -2.036274   Spain           Tejo       0          1   \n",
       "\n",
       "   Calib_EFI_Medit  Calib_connect  Calib_hydrol  ...  Squalius malacitanus  \\\n",
       "0                0              1             0  ...                     0   \n",
       "1                1              1             1  ...                     0   \n",
       "2                1              1             1  ...                     0   \n",
       "3                1              1             1  ...                     0   \n",
       "4                1              1             1  ...                     0   \n",
       "\n",
       "   Squalius pyrenaicus  Squalius torgalensis  Thymallus thymallus  \\\n",
       "0                    0                     0                    0   \n",
       "1                    0                     0                    0   \n",
       "2                    0                     0                    0   \n",
       "3                    0                     0                    0   \n",
       "4                    0                     0                    0   \n",
       "\n",
       "   Tinca tinca Zingel asper Squalius sp  Barbatula sp Phoxinus sp  \\\n",
       "0            0            0           0             0           0   \n",
       "1            0            0           0             0           0   \n",
       "2            0            0           0             0           0   \n",
       "3            0            0           0             0           0   \n",
       "4            0            0           0             0           0   \n",
       "\n",
       "   Iberochondrostoma_sp  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check multicolinearity in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MatrixLike' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alfor\\greends-avcd-2\\people\\Vasco Florentino\\class_8\\exercice8.ipynb Cell 4\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alfor/greends-avcd-2/people/Vasco%20Florentino/class_8/exercice8.ipynb#Y113sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m frame_scaled \u001b[39m=\u001b[39m StandardScaler\u001b[39m.\u001b[39mfit_transform(df, X\u001b[39m=\u001b[39mMatrixLike)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alfor/greends-avcd-2/people/Vasco%20Florentino/class_8/exercice8.ipynb#Y113sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_scaled \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39mframe_scaled, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alfor/greends-avcd-2/people/Vasco%20Florentino/class_8/exercice8.ipynb#Y113sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                 columns\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alfor/greends-avcd-2/people/Vasco%20Florentino/class_8/exercice8.ipynb#Y113sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df_scaled\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MatrixLike' is not defined"
     ]
    }
   ],
   "source": [
    "frame_scaled = StandardScaler.fit_transform(df, X=MatrixLike)\n",
    "df_scaled = pd.DataFrame(data=frame_scaled, \n",
    "                                columns=df.columns)\n",
    "df_scaled.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to run PCA.\n",
    "\n",
    "### 1.3 Select the number of Principal Components (PC)\n",
    "\n",
    "To select the number of PC, usually a Scree plot is produced to visualize the percentage of explained variance or the eigenvalues per component. Either the `elbow rule` - retaining all components before the point where the curve flattens out - or the `Kaiser's rule` - retaining components whose eigenvalues are greater than 1.\n",
    "\n",
    "First we run PCA for 11 components (number of original variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alfor\\greends-avcd-2\\people\\Vasco Florentino\\class_8\\exercice8.ipynb Cell 6\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alfor/greends-avcd-2/people/Vasco%20Florentino/class_8/exercice8.ipynb#Y115sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m11\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alfor/greends-avcd-2/people/Vasco%20Florentino/class_8/exercice8.ipynb#Y115sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pca\u001b[39m.\u001b[39mfit_transform(df_scaled)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=11)\n",
    "pca.fit_transform(df_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have run the PCA and now we can extract the proportion of explained variance and the eigenvalues as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues = pca.explained_variance_ # eigenvalues\n",
    "prop_var = pca.explained_variance_ratio_ # proportion of explained variance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the scree plot with proportion of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_numbers = np.arange(pca.n_components_) + 1\n",
    " \n",
    "plt.plot(PC_numbers, \n",
    "         prop_var,\n",
    "         'ro-')\n",
    "plt.title('Scree Plot', fontsize=20)\n",
    "plt.ylabel('Proportion of Variance', fontsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Elbow rule` is not easy to apply to our data.\n",
    "We can try to apply the `Kaiser's rule` and for that we need to plot the eigenvalues instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_numbers = np.arange(pca.n_components_) + 1\n",
    " \n",
    "plt.plot(PC_numbers, \n",
    "         eigenvalues,\n",
    "         'ro-')\n",
    "plt.title('Scree Plot', fontsize=20)\n",
    "plt.ylabel('Eigenvalues', fontsize=16)\n",
    "plt.axhline(y=1, color='r', \n",
    "            linestyle='--')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this rule, 4 components should be retained. However, just for the purpose of ilustrating how to produce a PCA biplot vlisualization, we will retain only two components.\n",
    "\n",
    "### 1.4 Visualize and interpret the PCA biplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "PC = pca.fit_transform(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_wine = pd.DataFrame(data = PC, \n",
    "                            columns = ['PC1', 'PC2'])\n",
    "pca_wine.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"score\" - Scores of each object (for each PC) - PC\n",
    "# \"coef\" - PCA variable loadings (for each PC) - pca.components_\n",
    "# labels - name of variables - list(df.columns)\n",
    "\n",
    "\n",
    "def biplot(score,coef,labels=None): \n",
    " \n",
    "    xs = score[:,0] # PC1 object scores\n",
    "    ys = score[:,1] # PC2 object scores \n",
    "    n = coef.shape[0] # number of dimensions (2)\n",
    "    scalex = 1.0/(xs.max() - xs.min()) # to rescale scores\n",
    "    scaley = 1.0/(ys.max() - ys.min()) # to rescale scores\n",
    "    plt.scatter(xs * scalex,ys * scaley,\n",
    "                s=6, \n",
    "                color='blue') # scatter plot using rescaled object scores\n",
    " \n",
    "    for i in range(n):\n",
    "        plt.arrow(0, 0, coef[i,0], \n",
    "                  coef[i,1],color = 'red',\n",
    "                  head_width=0.01,\n",
    "                  alpha = 0.5) # plot arrows for each variable\n",
    "        plt.text(coef[i,0]* 1.15, \n",
    "                 coef[i,1] * 1.15, \n",
    "                 labels[i], \n",
    "                 color = 'red', \n",
    "                 ha = 'center', \n",
    "                 va = 'center') # variable labels for each arrow\n",
    " \n",
    "    plt.xlabel(\"PC{}\".format(1))\n",
    "    plt.ylabel(\"PC{}\".format(2))    \n",
    " \n",
    " \n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Biplot of PCA')\n",
    " \n",
    "biplot(PC, \n",
    "       np.transpose(pca.components_), \n",
    "       list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same biplot but with colors expressing wine quality\n",
    "\n",
    "PC1 = pca_wine['PC1']/(pca_wine['PC1'].max() - pca_wine['PC1'].min())\n",
    "PC2 = pca_wine['PC2']/(pca_wine['PC2'].max() - pca_wine['PC2'].min())\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Biplot of PCA')\n",
    "sns.scatterplot(x=PC1,\n",
    "              y=PC2,\n",
    "              hue = df_wine['quality'].tolist(),\n",
    "              linewidth=0,\n",
    "              )\n",
    "\n",
    "n = np.transpose(pca.components_).shape[0] # number of dimensions (2)\n",
    "for i in range(n):\n",
    "        plt.arrow(0, 0, np.transpose(pca.components_)[i,0], \n",
    "                  np.transpose(pca.components_)[i,1], \n",
    "                  color = (0.1, 0.1, 0.1, 0.8),\n",
    "                  head_width=0.02) # plot arrows for each variable\n",
    "        plt.text(np.transpose(pca.components_)[i,0]* 1.15, \n",
    "                 np.transpose(pca.components_)[i,1] * 1.15, \n",
    "                 list(df.columns)[i], \n",
    "                 color = (0.1, 0.1, 0.1, 0.8), \n",
    "                 ha = 'center', \n",
    "                 va = 'center') # variable labels for each arrow\n",
    "plt.legend(title='Wine quality')\n",
    "plt.xlabel(\"PC{}\".format(1))\n",
    "plt.ylabel(\"PC{}\".format(2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Running PCA from scratch\n",
    "\n",
    "The code that follows computes the same PCA but without depending on any specific PCA function.\n",
    "\n",
    "NOTE: The first step - variable standardization - was already performed\n",
    "\n",
    "Step 2: compute the covariance matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x): \n",
    "    return (x.T @ x)/(x.shape[0]-1)\n",
    "\n",
    "cov_mat = covariance(df_scaled) # np.cov(X_std.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Compute the eigenvectors and eigenvalues of the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import eig\n",
    "\n",
    "# Eigendecomposition of covariance matrix\n",
    "eig_vals, eig_vecs = eig(cov_mat)\n",
    "\n",
    "# Adjusting the eigenvectors (loadings) that are largest in absolute value to be positive\n",
    "max_abs_idx = np.argmax(np.abs(eig_vecs), axis=0)\n",
    "signs = np.sign(eig_vecs[max_abs_idx, range(eig_vecs.shape[0])])\n",
    "eig_vecs = eig_vecs*signs[np.newaxis,:]\n",
    "eig_vecs = eig_vecs.T\n",
    "\n",
    "print('Eigenvalues \\n', eig_vals)\n",
    "print('Eigenvectors \\n', eig_vecs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Rearrange the eigenvectors and eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of eigenvalue and eigenvector tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[i,:]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the tuples from the highest to the lowest eigenvalues\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# For further usage\n",
    "eig_vals_sorted = np.array([x[0] for x in eig_pairs])\n",
    "eig_vecs_sorted = np.array([x[1] for x in eig_pairs])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Select the number of PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top k eigenvectors\n",
    "k = 2\n",
    "W = eig_vecs_sorted[:k, :] # Projection matrix\n",
    "\n",
    "eig_vals_total = sum(eig_vals)\n",
    "explained_variance = [(i / eig_vals_total)*100 for i in eig_vals_sorted]\n",
    "explained_variance = np.round(explained_variance, 2)\n",
    "cum_explained_variance = np.cumsum(explained_variance)\n",
    "\n",
    "print('Explained variance: {}'.format(explained_variance))\n",
    "print('Cumulative explained variance: {}'.format(cum_explained_variance))\n",
    "\n",
    "plt.plot(np.arange(1, 11 + 1), cum_explained_variance, '-o')\n",
    "plt.xticks(np.arange(1,11+1))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance');\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Project the data with a biplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "X_proj = df_scaled.dot(W.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create biplot\n",
    "PC1 = X_proj.iloc[:, 0]/(X_proj.iloc[:, 0].max() - X_proj.iloc[:, 0].min())\n",
    "PC2 =X_proj.iloc[:, 1]/(X_proj.iloc[:, 1].max() - X_proj.iloc[:, 1].min())\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('2 components, captures {:.1f} of total variation'.format(cum_explained_variance[1]))\n",
    "\n",
    "sns.scatterplot(x=PC1,\n",
    "              y=PC2,\n",
    "              hue = df_wine['quality'].tolist(),\n",
    "              linewidth=0,\n",
    "              )\n",
    "\n",
    "n = np.transpose(pca.components_).shape[0] # number of dimensions (2)\n",
    "for i in range(n):\n",
    "        plt.arrow(0, 0, np.transpose(pca.components_)[i,0], \n",
    "                  np.transpose(pca.components_)[i,1], \n",
    "                  color = (0.1, 0.1, 0.1, 0.8),\n",
    "                  head_width=0.02) # plot arrows for each variable\n",
    "        plt.text(np.transpose(pca.components_)[i,0]* 1.15, \n",
    "                 np.transpose(pca.components_)[i,1] * 1.15, \n",
    "                 list(df.columns)[i], \n",
    "                 color = (0.1, 0.1, 0.1, 0.8), \n",
    "                 ha = 'center', \n",
    "                 va = 'center') # variable labels for each arrow\n",
    "plt.legend(title='Wine quality')\n",
    "plt.xlabel(\"PC{}\".format(1))\n",
    "plt.ylabel(\"PC{}\".format(2))\n",
    "\n",
    "plt.xlabel('PC1'); plt.xticks([])\n",
    "plt.ylabel('PC2'); plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Multidimensional Scaling (MDS) and Non-Metric Multidimensional Scaling\n",
    "\n",
    "The aim of this ordination method is to project objects from a higher-dimensional space to a lower-dimensional space while preserving the relative distances between those points as much as possible. PCoA (also known as MDS) can be viewed as a generalization of PCA that allows a much wider range of dissimilarity measures to be used (dissimilarities among objects in PCA are euclidean distances).\n",
    "\n",
    "MDS and NMDS are implemented in the `mds()` function of `sklearn.manifold` module.\n",
    "\n",
    "#### 1.1 Import modules and functions\n",
    "\n",
    "Import necessary modules and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics.pairwise import manhattan_distances, euclidean_distances\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Run MDS\n",
    "\n",
    "We will run MDS using the same wine dataset used in PCA. We will use the standardized data (df_scaled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default the 'mds' argument is set to 'True', which means it will run a MDS\n",
    "# Euclidean distances are also the default \n",
    "# Only two axis are extracted by default\n",
    "mds = MDS(random_state=0, normalized_stress = False) \n",
    "mds_transf = mds.fit_transform(df_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=mds_transf[:,0],\n",
    "              y=mds_transf[:,1],\n",
    "              hue = df_wine['quality'].tolist(),\n",
    "              linewidth=0,\n",
    "              )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may use other distances to compute MDS. For that we need to run the function using a dissimilarity matrix as the input.\n",
    "Let's try running MDS with Manhattan dissimilarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_manhattan = manhattan_distances(df_scaled)\n",
    "mds = MDS(dissimilarity='precomputed', random_state=0, normalized_stress = False)\n",
    "mds_transf2 = mds.fit_transform(dist_manhattan)\n",
    "\n",
    "sns.scatterplot(x=mds_transf2[:,0],\n",
    "              y=mds_transf2[:,1],\n",
    "              hue = df_wine['quality'].tolist(),\n",
    "              linewidth=0,\n",
    "              )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Run NMDS\n",
    "\n",
    "Non-Metric Multidimensional Scaling solved many issues of MDS, namely the computation of the meaured used to evaluate how much the distances in the MDS are related with the original dissimilarities. This methods is based on ranks of distances among objects, so the aim is to retain the relative position of objects from each other, not their distances. It is based on a iterative trial & error algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmds = MDS(n_components=5, random_state=0, metric = False, normalized_stress=\"auto\") # 5 components extracted so that stress is > 0.2\n",
    "nmds_transf = nmds.fit_transform(df_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The match between object distance in MDS and the original dissimilarities is given by the stress, which is proportional to the residuals of that relationship. The stress of an MDS with a perfect match between MDS distances and original dissimilarities will be closer to zero. \n",
    "\n",
    "As a rule of thumb, an NMDS ordination with a stress value around or above 0.2 is deemed suspect and a stress value approaching 0.3 indicates that the ordination is arbitrary. Stress values equal to or below 0.1 are considered fair, while values equal to or below 0.05 indicate good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress = nmds.stress_\n",
    "print(stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=nmds_transf[:,0],\n",
    "              y=nmds_transf[:,1],\n",
    "              hue = df_wine['quality'].tolist(),\n",
    "              linewidth=0,\n",
    "              )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use the method with dissimilarities other than Euclidean distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMDS based on Manhattan distances\n",
    "nmds2 = MDS(metric = False, random_state=0, normalized_stress = 'auto', dissimilarity='precomputed')\n",
    "nmds_transf2 = nmds2.fit_transform(dist_manhattan)\n",
    "\n",
    "sns.scatterplot(x=nmds_transf2[:,0],\n",
    "              y=nmds_transf2[:,1],\n",
    "              hue = df_wine['quality'].tolist(),\n",
    "              linewidth=0,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress = nmds2.stress_\n",
    "print(stress)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
