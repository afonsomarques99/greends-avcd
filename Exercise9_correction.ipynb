{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Visualization of Complex Agro-Environmental Data\n",
    "---\n",
    "### Exercise #9 - correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 9.1 - NOTE: to be more interesting it is better to consider more catchments, so the Minho and Mondego catchments were also considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('EFIplus_medit.zip',compression='zip', sep=\";\")\n",
    "df = df.dropna() # remove all rows with missing data\n",
    "# Subset the df by selecting the environmental variables and the species richness columns\n",
    "dfsub = df[(df['Catchment_name']=='Douro') | (df['Catchment_name']=='Tejo') | (df['Catchment_name']=='Minho') | (df['Catchment_name']=='Mondego')]\n",
    "df_env = dfsub[[\"Altitude\", \"Actual_river_slope\",\"Elevation_mean_catch\", \"prec_ann_catch\",\"temp_ann\",\"temp_jan\",\"temp_jul\"]]\n",
    "df_catch = dfsub[[\"Catchment_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efi_scaled = StandardScaler().fit_transform(df_env)\n",
    "# As a result, we obtained a two-dimensional NumPy array. We can convert it to a pandas DataFrame for a better display.\n",
    "df_scaled = pd.DataFrame(data=efi_scaled, \n",
    "                                columns=df_env.columns)\n",
    "df_scaled.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define predictor and response variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled\n",
    "y = dfsub['Catchment_name'] # 4 classes (Tagus, Douro and Minho and Mondego)\n",
    "\n",
    "#Fit the LDA model\n",
    "model = LinearDiscriminantAnalysis(n_components=2)\n",
    "DLA = model.fit_transform(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the first two discriminant axis to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DLA_scores = pd.DataFrame(data = DLA, \n",
    "                            columns = ['LD1', 'LD2'])\n",
    "DLA_scores.head(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define method to evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8869966209501093\n"
     ]
    }
   ],
   "source": [
    "#defines the kfold crossvalidation settings for the next function 'cross_val_score'\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1) \n",
    "\n",
    "#evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the fist discriminant plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.scatterplot(x=DLA_scores['LD1'],\n",
    "              y=DLA_scores['LD2'],\n",
    "              hue = dfsub['Catchment_name'].tolist(),\n",
    "              linewidth=0,\n",
    "              )\n",
    "\n",
    "n = model.n_features_in_\n",
    "for i in range(n):\n",
    "        plt.arrow(0, 0, model.scalings_[i,0]*2, # Scalings were multiplied by a factor of 4 to just to facilitate the visualization\n",
    "                  model.scalings_[i,1]*2, # Scalings were multiplied by a factor of 4 to just to facilitate the visualization\n",
    "                  color = (0.1, 0.1, 0.1, 0.8),\n",
    "                  head_width=0.02) # plot arrows for each variable\n",
    "        plt.text(model.scalings_[i,0]*2.1, # plot the names of the variables\n",
    "                 model.scalings_[i,1]*2.1,\n",
    "                 list(df_scaled)[i], \n",
    "                 color = (0.1, 0.1, 0.1, 0.8), \n",
    "                 ha = 'center', \n",
    "                 va = 'center') # variable labels for each arrow\n",
    "\n",
    "plt.xlabel('LD1')\n",
    "plt.ylabel('LD2')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 9.2 Interactive plot using Dash\n",
    "\n",
    "Copy the following code to a python file (e.g. \"DLA-visual.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "# import Dash, dcc (stands for Dash Core Components - this module includes a Graph component called dcc.Graph, \n",
    "# which is used to render interactive graphs amd dcc.slider to render an interactive slider).\n",
    "# We also import sklearn.decomposition.PCA to run a PCA, the plotly.express library to build the interactive graphs, \n",
    "# and pandas to work with DataFrames.\n",
    "\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Initialize the app\n",
    "# This line is known as the Dash constructor and is responsible for initializing your app. \n",
    "# It is almost always the same for any Dash app you create.\n",
    "app = Dash(__name__)\n",
    "\n",
    "# App layout\n",
    "# The app layout represents the app components that will be displayed in the web browser, \n",
    "# normally contained within a html.Div.\n",
    "app.layout = html.Div([\n",
    "    html.H4(\"Visualization of LDA explained variance\", style={'textAlign':'center'}),\n",
    "    dcc.Graph(id=\"LDA-visualization-x-graph\"),\n",
    "    html.P(\"Number of components:\"),\n",
    "    dcc.Slider(\n",
    "        id='LDA-visualization-x-slider',\n",
    "        min=2, max=3, value=2, step=1)\n",
    "])\n",
    "\n",
    "# Add controls to build the interaction\n",
    "# The inputs and outputs of our app are the properties of a particular component. \n",
    "# The output is the figure property of the component with the ID \"pca-visualization-x-graph\"\n",
    "# THe input is the value property of the component that has the ID \"pca-visualization-x-slider\".\n",
    "# The callback function's argument 'n_components' refers to the component property of the input. \n",
    "# We build PCA plots inside the callback function, assigning the chosen value in the slider. \n",
    "# This means that every time the user selects the number of components with the slider, the figure is rebuilt\n",
    "# to add more or less components\n",
    "# Finally, we return the scatter plots at the end of the function. \n",
    "# This assigns the plots to the figure property of the dcc.Graph, thus displaying the figure in the app.\n",
    "@app.callback(\n",
    "    Output(component_id=\"LDA-visualization-x-graph\", component_property=\"figure\"), \n",
    "    Input(component_id=\"LDA-visualization-x-slider\", component_property=\"value\"))\n",
    "\n",
    "\n",
    "def run_and_plot(n_components):\n",
    "    df = pd.read_csv('EFIplus_medit.zip',compression='zip', sep=\";\")\n",
    "    df = df.dropna() # remove all rows with missing data\n",
    "    # Subset the df by selecting the environmental variables and the species richness columns\n",
    "    dfsub = df[(df['Catchment_name']=='Douro') | (df['Catchment_name']=='Tejo') | (df['Catchment_name']=='Minho') | (df['Catchment_name']=='Mondego')]\n",
    "    df_env = dfsub[[\"Altitude\", \"Actual_river_slope\",\"Elevation_mean_catch\", \"prec_ann_catch\",\"temp_ann\",\"temp_jan\",\"temp_jul\"]]\n",
    "    df_catch = dfsub[[\"Catchment_name\"]]\n",
    "    efi_scaled = StandardScaler().fit_transform(df_env)\n",
    "    # As a result, we obtained a two-dimensional NumPy array. We can convert it to a pandas DataFrame for a better display.\n",
    "    df_scaled = pd.DataFrame(data=efi_scaled, columns=df_env.columns)\n",
    "    X = df_scaled\n",
    "    y = dfsub['Catchment_name'] # 4 classes (Tagus, Douro and Minho and Mondego)\n",
    "    model = LinearDiscriminantAnalysis(n_components=n_components) # defines the number of components in the PCA\n",
    "    components = model.fit_transform(X, y) # fits a PCA\n",
    "    var = model.explained_variance_ratio_.sum() * 100 # % of explained variance by each PC\n",
    "    labels = {str(i): f\"DC {i+1}\" for i in range(n_components)} # PC labels\n",
    "    labels['color'] = 'quality'\n",
    "    fig = px.scatter_matrix(\n",
    "        components,\n",
    "        color=dfsub['Catchment_name'],\n",
    "        dimensions=range(n_components),\n",
    "        labels=labels,\n",
    "        title=f'Total Explained Variance: {var:.2f}%',\n",
    "        width=1400, height=1300\n",
    "        )\n",
    "    fig.update_traces(diagonal_visible=False)\n",
    "    return fig\n",
    "\n",
    "# Run the app - These lines are for running your app, and they are almost always the same for any Dash app you create.\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
