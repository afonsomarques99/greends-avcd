{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Visualization of Complex Agro-Environmental Data\n",
    "---\n",
    "## Data transformation\n",
    "\n",
    "### 1. Reshaping Pandas DataFrames by stacking/unstacking and pivoting\n",
    "\n",
    "In many situations, it is important to reshape the data tables to prepare data to be analysed or visualized using certain functions. Here, the most common reshaping operations are demonstrated.\n",
    "\n",
    "#### Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hold  Year       Fruit  Production\n",
      "0     A  2001  strawberry        1000\n",
      "1     B  2001  blackberry         300\n",
      "2     C  2001   raspberry         400\n",
      "3     D  2001  blue berry         500\n",
      "4     A  2002  gooseberry         800\n",
      "5     C  2002  strawberry        1000\n",
      "6     B  2002  blackberry         500\n",
      "7     C  2002   raspberry         700\n",
      "8     A  2003  blue berry          50\n",
      "9     A  2003  gooseberry          60\n",
      "10    A  2003  strawberry        1000\n",
      "11    B  2003  blackberry         900\n",
      "12    C  2004   raspberry         750\n",
      "13    D  2004  blue berry         200\n",
      "14    C  2004  gooseberry         300\n",
      "15    B  2004  strawberry        1000\n",
      "16    B  2005  blackberry         900\n",
      "17    C  2005   raspberry         250\n",
      "18    D  2005  blue berry         750\n",
      "19    A  2005  gooseberry          50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Hold': ['A', 'B', 'C', 'D', 'A', 'C', 'B', 'C', 'A', 'A', 'A', 'B', 'C', 'D', 'C', 'B', 'B', 'C', 'D', 'A'],\n",
    "        'Year': [2001, 2001, 2001, 2001, 2002, 2002, 2002, 2002, 2003, 2003, 2003, 2003, 2004, 2004, 2004, 2004, 2005, 2005, 2005, 2005],\n",
    "        'Fruit': ['strawberry', 'blackberry', 'raspberry', 'blue berry', 'gooseberry', 'strawberry', 'blackberry', 'raspberry', 'blue berry', 'gooseberry', 'strawberry', 'blackberry', 'raspberry', 'blue berry', 'gooseberry', 'strawberry', 'blackberry', 'raspberry', 'blue berry', 'gooseberry'],\n",
    "        'Production': [1000, 300, 400, 500, 800, 1000, 500, 700, 50, 60, 1000, 900, 750, 200, 300, 1000, 900, 250, 750, 50],\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stack and Unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstack part\n",
    "df2 = df[['Fruit', 'Hold', 'Production']]\n",
    "df2 = df2.set_index(['Hold', 'Fruit'], append=True)\n",
    "df2Unstack = df2.unstack()\n",
    "df2Unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstack part ('Hold' as columns)\n",
    "df2 = df[['Fruit', 'Hold', 'Production']]\n",
    "df2 = df2.set_index(['Hold', 'Fruit'], append=True)\n",
    "df2unstack = df2.unstack(level=1)\n",
    "df2unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack\n",
    "df2stack = df2unstack.stack()\n",
    "df2stack"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot table\n",
    "\n",
    "A more useful and versatile function to unstack a data table is the pandas' pivot_table() function. After normalizing a given dataset, it is frequently useful to pivoting a table in order to convert a categorical variable with n classes into n separate variables. The values may represent different  summarizations of a continuous variable associated to each category, such as the sum, the mean, the maximum, ...\n",
    "\n",
    "Run the examples below using the same DataFrame created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Fruit</th>\n",
       "      <th>blackberry</th>\n",
       "      <th>blue berry</th>\n",
       "      <th>gooseberry</th>\n",
       "      <th>raspberry</th>\n",
       "      <th>strawberry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>2600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Fruit  blackberry  blue berry  gooseberry  raspberry  strawberry\n",
       "Hold                                                            \n",
       "A             NaN        50.0       910.0        NaN      2000.0\n",
       "B          2600.0         NaN         NaN        NaN      1000.0\n",
       "C             NaN         NaN       300.0     2100.0      1000.0\n",
       "D             NaN      1450.0         NaN        NaN         NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(\n",
    "    data=df,\n",
    "    index='Hold', # lines will be indexed by 'Hold'\n",
    "    columns='Fruit', # Columns defined by the 'Fruit' categories\n",
    "    values='Production', # The values in the resulting table\n",
    "    aggfunc='sum' # sums the production by 'Hold'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(\n",
    "    data=df,\n",
    "    index='Hold',\n",
    "    columns=['Fruit','Year'], # Columns defined by the 'Fruit' and 'Year' categories\n",
    "    values='Production'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(\n",
    "    data=df,\n",
    "    index=['Hold', 'Year'],# lines will be indexed by 'Hold' and 'Year'\n",
    "    columns='Fruit',\n",
    "    values='Production'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Variable standardization and normalization\n",
    "\n",
    "Variable standardization is used in many situations, namely when analyses involve variables measured in different units. It provides methods of rescaling variables without changing the probability distributions of the original data. It is a requirement and a common practice when certain statistical approaches and modelling algorithms are applied to data. For example, in regression-based methods, it allows to directly compare the effect sizes of variables that are measured in very different units; in some multivariate statistical approaches, it avoids giving very varying weights to variables measured in different units; when applying certain modelling algorithms such as Generalized Linar Mixed Models, a previous data standardization is a requirement.\n",
    "\n",
    "The most commonly used standardization method involves centering and scaling operations (Z-score standardization), i.e., each observation  is subtracted by the mean and divided by the standard deviation, so that the new standardized variables has mean = 0 and the standard deviation = 1. After this standardization transformation, the transformed data is often called Z-score.\n",
    "\n",
    "Standardizing variables is quite straightforward in python. Even so, there are some modules that implement variable standardization functions, such as the StandardScaler() function of the sklearn module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standardize single variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = sts.norm.rvs(scale=50, loc=150, size=1000)\n",
    "sns.histplot(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varstd = (var-var.mean())/var.std()\n",
    "sns.histplot(varstd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively:\n",
    "# Import Z-Score Standard Scaler from the Sklearn package\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2 = pd.DataFrame(var)\n",
    "varstd2 = scale.fit_transform(var2)\n",
    "sns.histplot(varstd2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standardize several predictor variables at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create data frame\n",
    "df3 = pd.DataFrame({'y': [8, 12, 15, 14, 19, 23, 25, 29],\n",
    "                   'x1': [5, 7, 7, 9, 12, 9, 9, 4],\n",
    "                   'x2': [11, 8, 10, 6, 6, 5, 9, 12],\n",
    "                   'x3': [2, 2, 3, 2, 5, 5, 7, 9]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define predictor variable columns\n",
    "df3_x = df3[['x1', 'x2', 'x3']]\n",
    "\n",
    "# standardize the values for each predictor variable - replace values in df by stadardized ones\n",
    "df3[['x1', 'x2', 'x3']] = (df3_x-df3_x.mean())/df3_x.std()\n",
    "\n",
    "#view new data frame\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view mean of each predictor variable column\n",
    "df3[['x1', 'x2', 'x3']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view standard deviation of each predictor variable column\n",
    "df3[['x1', 'x2', 'x3']].std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize data using min-max scaler\n",
    "\n",
    "It normalizes the data into a range between 0 and 1 based on the formula: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define predictor variable columns\n",
    "df4 = df3\n",
    "df4_x = df4[['x1', 'x2', 'x3']]\n",
    "\n",
    "# standardize the values for each predictor variable - replace values in df by stadardized ones\n",
    "df4[['x1', 'x2', 'x3']] = (df4_x-df4_x.min())/(df4_x.max()-df4_x.min())\n",
    "df4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Variable transformation\n",
    "\n",
    "Variable transformation is a very commonly used procedure to prevent some potential statistical problems, especially when using parametric hypothesis testing such as t-test or regression-based methods. It is especially used to tranform variables with very skewed distributions to become more belly shaped. \n",
    "\n",
    "Logarithmic transformation is one of the most commonly used. A more general and complex transformations are the Box-Cox transformations, which involves the estimation of a parameter (lambda) to approximate as much as possible the variable to a normal distribution. For proportions, angular transformations such as the arcsin are more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = sts.expon.rvs(scale=1, loc=0, size=1000)\n",
    "sns.histplot(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logarithmic transformation\n",
    "varlog = np.log10(var)\n",
    "sns.histplot(varlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square-root transformation\n",
    "varsqrt = np.sqrt(var)\n",
    "sns.histplot(varsqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cube-root transformation\n",
    "varcbrt = np.cbrt(var)\n",
    "sns.histplot(varcbrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-cox transformation\n",
    "from scipy import stats\n",
    "fitted_data, fitted_lambda = stats.boxcox(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# creating axes to draw plots\n",
    "fig, ax = plt.subplots(1, 2)\n",
    " \n",
    "# plotting the original data(non-normal) and\n",
    "# fitted data (normal)\n",
    "sns.histplot(var, kde = True,\n",
    "            label = \"Original\", ax = ax[0]).legend(loc = \"upper right\")\n",
    " \n",
    "sns.histplot(fitted_data, kde = True,\n",
    "            label = \"Transformed\", ax = ax[1]).legend(loc = \"upper right\")\n",
    "\n",
    "# rescaling the subplots\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(10)\n",
    " \n",
    "print(f\"Lambda value used for Transformation: {fitted_lambda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the values for each predictor variable in a table - replace values in df3 (see above) by standardized ones\n",
    "df3[['x1', 'x2', 'x3']] = np.log10(df3[['x1', 'x2', 'x3']])\n",
    "df3\n",
    "# Alternative:\n",
    "# df3[['x1', 'x2', 'x3']] = df3[['x1', 'x2', 'x3']].apply(np.log10) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Engineer features in the data\n",
    "\n",
    "This kind of data transformation involves generating new variables from existing ones. A common procedure is to aggregate values for each category of a factor, using functions such as the sum, the mean, maximum, ... In other situations, new variables are generated simply by applying a given function (e.g. sum) to a set of columns in a data table.\n",
    "\n",
    "A usefull function to generate new variables is again the pandas' pivot_table(), as shown by the  examples that follows using the df DataFrame generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the sum of each fruit production from df\n",
    "df.pivot_table(index=['Fruit'], values=['Production'], aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the sum of each fruit production at each farm hold\n",
    "df.pivot_table(index=['Fruit', 'Hold'], values=['Production'], aggfunc='sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the median, mean, max and sum of each fruit production per farm hold and year\n",
    "df.pivot_table(index=['Year','Fruit', 'Hold'], values=['Production'], aggfunc={'median', 'mean', 'max', 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a new variable from summing variables x1, x2 and x3 of df3 generated above.\n",
    "df3['Sum'] = df3[['x1', 'x2', 'x3']].sum(axis=1) # Sums the  variables and adds new variable called 'Sum'\n",
    "df3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Beginner Explanation for Data Transformation, https://towardsdatascience.com/beginner-explanation-for-data-transformation-9add3102f3bf\n",
    "\n",
    "How to Standardize Data in Python (With Examples), https://www.statology.org/standardize-data-python/\n",
    "\n",
    "Normalize a Pandas Column or Dataframe (w/ Pandas or sklearn), https://datagy.io/pandas-normalize-column/\n",
    "\n",
    "Python | Box-Cox Transformation, https://www.geeksforgeeks.org/box-cox-transformation-using-python/\n",
    "\n",
    "Pivot Tables in Pandas with Python, https://datagy.io/python-pivot-tables/\n",
    "\n",
    "Transformations of Stack, Melt, Pivot Table in pandas, https://towardsdatascience.com/transformations-of-stack-melt-pivot-table-901292196d9e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
