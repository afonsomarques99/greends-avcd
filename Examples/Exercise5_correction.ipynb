{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Visualization of Complex Agro-Environmental Data\n",
    "---\n",
    "### Exercise #5 - correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import seaborn as sns # For plotting\n",
    "import matplotlib.pyplot as plt # For showing plots\n",
    "import scipy.stats as sts\n",
    "import scikit_posthocs as sp\n",
    "import statsmodels.stats as stm\n",
    "from statsmodels.graphics.gofplots import qqplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('EFIplus_medit.zip',compression='zip', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the dataset to remove unnecessary columns (eg. REG) \n",
    "df.drop(df.iloc[:,5:15], axis=1, inplace=True)\n",
    "\n",
    "# let's rename some columns so that they make sense\n",
    "df.rename(columns={'Sum of Run1_number_all':'Total_fish_individuals'}, inplace=True) # inplace=\"True\" means that df will be updated\n",
    "\n",
    "# for sake of consistency, let's also make all column labels of type string\n",
    "df.columns = list(map(str, df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a good way of detecting missing values in the dataset\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.heatmap(df.isnull(),cbar=False,cmap='viridis',yticklabels=False)\n",
    "plt.title('Missing values (yellow) in the dataset');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce contingency table of Country and Samo trutta fario.\n",
    "cdf = pd.crosstab(index=df['Country'], columns=df['Salmo trutta fario'])\n",
    "print(cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square test of independency\n",
    "stat, p, df, expected = sts.chi2_contingency(cdf)\n",
    "print('df=%d' % df)\n",
    "print('expected values:')\n",
    "print(expected)\n",
    "# interpret test-statistic\n",
    "prob=0.95\n",
    "critical = sts.chi2.ppf(prob, df)\n",
    "print('critical=%.3f, stat=%.3f' % (critical, stat))\n",
    "if abs(stat) >= critical:\n",
    " print('reject H0 that variables are independent')\n",
    "else:\n",
    " print('fail to reject H0 that variables are independent')\n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print('significance=%.2f, p=%.3f' % (alpha, p))\n",
    "if p <= alpha:\n",
    " print('reject H0 that variables are independent')\n",
    "else:\n",
    " print('fail to reject H0 that variables are independent')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df2, x='Salmo trutta fario', y='Actual_river_slope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat=439968.000, p-value=0.000\n",
      "reject H0 that median values are equal\n",
      "Median of sample 1 = 4.05\n",
      "Median of sample 2 = 10.70\n"
     ]
    }
   ],
   "source": [
    "# Run Mann-Whitney U test - t test would be inadequate as actual_river_slope is very far from normality and has many outliers (see exercise 4)\n",
    "df2 = df.dropna() # need to remove missing data (will not run with missing data)\n",
    "\n",
    "sample1 = df2[df2['Salmo trutta fario']==0]['Actual_river_slope']\n",
    "sample2 = df2[df2['Salmo trutta fario']==1]['Actual_river_slope']\n",
    "\n",
    "Meds1 = sample1.median()\n",
    "Meds2 = sample2.median()\n",
    "\n",
    "stat, p = sts.mannwhitneyu(sample1, sample2, alternative='two-sided')\n",
    "print('stat=%.3f, p-value=%.3f' % (stat, p))\n",
    "alpha = 0.05\n",
    "if p <= alpha:\n",
    " print('reject H0 that median values are equal')\n",
    "else:\n",
    " print('fail to reject H0')\n",
    "\n",
    "print('Median of sample 1 = %.2f' % Meds1)\n",
    "print('Median of sample 2 = %.2f' % Meds2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment_count = pd.crosstab(index = df['Catchment_name'], columns='count')\n",
    "catchment_count.sort_values(by=['count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "dfsub = df2[(df2['Catchment_name']=='Ebro') | \n",
    "    (df2['Catchment_name']=='Galiza-Norte') |\n",
    "    (df2['Catchment_name']=='Minho') |\n",
    "    (df2['Catchment_name']=='Tejo')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['Actual_river_slope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "qqplot(pd.Series(df2['Elevation_mean_catch']), line='s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although the distribution of the mean elevation is right skewed and seems to depart from normality we will nevertheless try to run ANOVA. \n",
    "\n",
    "mod = ols('Elevation_mean_catch ~ Catchment_name',\n",
    "                data=dfsub).fit()\n",
    "                \n",
    "aov_table = sm.stats.anova_lm(mod, typ=2) # typ is the type of anova type to perform ('I','II' or 'III' = 1,2,3)\n",
    "print(aov_table) # provides the usual ANOVA table\n",
    "\n",
    "alpha=0.05\n",
    "p=aov_table['PR(>F)'][0]\n",
    "\n",
    "if p <= alpha:\n",
    " print('reject H0 that mean elevation values are equal among catchments')\n",
    "else:\n",
    " print('fail to reject H0 that mean elevation values are equal among catchments')\n",
    "\n",
    "# compute mean elevation for eacch catchment\n",
    "dfsub[['Elevation_mean_catch','Catchment_name']].groupby('Catchment_name').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple comparisons - perform Tukey's test \n",
    "tukey = stm.multicomp.pairwise_tukeyhsd(endog=dfsub['Elevation_mean_catch'],\n",
    "                          groups=dfsub['Catchment_name'],\n",
    "                          alpha=0.05)\n",
    "#display results\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=dfsub, x='Catchment_name', y='Actual_river_slope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run non-parametric equivalent to one-way ANOVA - Kruskal-Walis test\n",
    "sample1 = df2[(df2['Catchment_name']=='Ebro')]['Elevation_mean_catch']\n",
    "sample2 = df2[(df2['Catchment_name']=='Galiza-Norte')]['Elevation_mean_catch']\n",
    "sample3 = df2[(df2['Catchment_name']=='Minho')]['Elevation_mean_catch']\n",
    "sample4 = df2[(df2['Catchment_name']=='Tejo')]['Elevation_mean_catch']\n",
    "\n",
    "stat, p = sts.kruskal(sample1, sample2, sample3, sample4)\n",
    "print('F-statistics=%.3f, p=%.6f' % (stat, p))\n",
    "\n",
    "alpha=0.05\n",
    "\n",
    "if p <= alpha:\n",
    " print('reject H0 that median elevation values are equal among catchments')\n",
    "else:\n",
    " print('fail to reject H0 that median elevation values are equal among catchments')\n",
    "\n",
    "# Compute median values of Mean elevation for each catchment\n",
    "dfsub[['Elevation_mean_catch','Catchment_name']].groupby('Catchment_name').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-parametric multiple comparisons: Dunn's test\n",
    "# need to produce a list with samples\n",
    "list_sample = [sample1, sample2, sample2, sample4]\n",
    "sp.posthoc_dunn(list_sample, p_adjust = 'bonferroni') # the correction for multiple comparisons is based on the bonferroni's correction.\n",
    "# the output is a matrix of p-values for each pair of groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 5.4\n",
    "\n",
    "Potential problems in the data used for hypothesis testing is that categories are highly unbalanced (very different number of samples for each category - see below). Another potential problem is the lak of independency among sampling sites. For example when we tested the effect of Actual_river_slope in the presence of Salmo trutta fario, we did not take into account that observations within each catchment might not be totally independent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfsub['Catchment_name'].value_counts())\n",
    "print(df['Salmo trutta fario'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
